# ğŸ¯ Lentra

> Local multi-model RAG playground with side-by-side evaluation and character-driven UI

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/)
[![Next.js](https://img.shields.io/badge/Next.js-14+-black.svg)](https://nextjs.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸŒŸ Overview

Lentra (ArenaLLM) is a **local AI playground** designed to:

- ğŸ¤– Run multiple local LLMs simultaneously
- ğŸ“š Test RAG (Retrieval-Augmented Generation) pipelines
- âš–ï¸ Compare model outputs side-by-side
- ğŸ† Score and evaluate responses
- ğŸ­ Present each model as a distinct "character"

### Target Users

- AI/ML Engineers
- Researchers
- Builders evaluating models for production

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Frontend UI         â”‚
â”‚  (Next.js + WebGL Layer)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ REST / WS
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        API Gateway         â”‚
â”‚         (FastAPI)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Orchestration Layer    â”‚
â”‚  (Model + RAG Controller)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RAG Engine â”‚ â”‚ LLM Runnerâ”‚
â”‚  (Retrieval) â”‚ â”‚  Adapters â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Vector Store â”‚ â”‚ Local LLMs â”‚
â”‚   (FAISS)    â”‚ â”‚  (Ollama)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

See [ARCHITECTURE.md](./ARCHITECTURE.md) for detailed documentation.

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- Node.js 20+
- [Ollama](https://ollama.ai/) installed and running
- At least one model pulled (e.g., `ollama pull llama3.1:8b`)

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/lentra.git
cd lentra

# Run setup script
chmod +x scripts/setup.sh
./scripts/setup.sh

# Or manual setup:

# Backend
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt

# Frontend
cd ../frontend
npm install
```

### Configuration

```bash
# Copy environment template
cp .env.example .env

# Edit with your settings
nano .env
```

### Development

```bash
# Start both frontend and backend
./scripts/dev.sh

# Or separately:

# Backend (from /backend)
source venv/bin/activate
uvicorn src.main:app --reload --port 8000

# Frontend (from /frontend)
npm run dev
```

### Access

- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs

## ğŸ“ Project Structure

```
lentra/
â”œâ”€â”€ backend/                 # FastAPI backend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/            # Route handlers
â”‚   â”‚   â”œâ”€â”€ core/           # Config, logging, exceptions
â”‚   â”‚   â”œâ”€â”€ models/         # LLM adapters & runner
â”‚   â”‚   â”œâ”€â”€ rag/            # RAG engine components
â”‚   â”‚   â”œâ”€â”€ evaluation/     # Comparator & strategies
â”‚   â”‚   â””â”€â”€ schemas/        # Pydantic models
â”‚   â””â”€â”€ tests/              # pytest tests
â”œâ”€â”€ frontend/               # Next.js frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/           # Next.js app router
â”‚   â”‚   â”œâ”€â”€ components/    # React components
â”‚   â”‚   â”œâ”€â”€ hooks/         # Custom hooks
â”‚   â”‚   â”œâ”€â”€ lib/           # Utilities
â”‚   â”‚   â”œâ”€â”€ services/      # API clients
â”‚   â”‚   â””â”€â”€ types/         # TypeScript types
â”‚   â””â”€â”€ tests/             # Vitest tests
â”œâ”€â”€ common/                 # Shared types/contracts
â”œâ”€â”€ scripts/               # Dev & deployment scripts
â”œâ”€â”€ docker/                # Docker configurations
â””â”€â”€ .github/               # CI/CD workflows
```

## ğŸ§ª Testing

```bash
# Backend tests
cd backend
source venv/bin/activate
pytest

# Frontend tests
cd frontend
npm run test
```

## ğŸ³ Docker

```bash
# Build and run with Docker Compose
docker-compose -f docker/docker-compose.yml up --build
```

## ğŸ“– API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/prompt` | Submit prompt to multiple models |
| POST | `/rag/query` | Query with RAG context |
| GET | `/models` | List available models |
| GET | `/models/{id}` | Get model details |
| POST | `/evaluate` | Evaluate/compare responses |

## ğŸ” Security

- All data stays local (no cloud dependency)
- No telemetry by default
- Secrets managed via environment variables
- Input sanitization on all endpoints

## ğŸ›£ï¸ Roadmap

- [x] Project scaffolding
- [x] Ollama adapter implementation
- [x] Basic RAG with FAISS
- [ ] Side-by-side comparison UI
- [ ] Evaluation strategies
- [ ] Character/avatar system
- [ ] Additional LLM adapters

## ğŸ¤ Contributing

1. Read [ARCHITECTURE.md](./ARCHITECTURE.md)
2. Follow coding standards
3. Write tests for new features
4. Submit PR with description

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

---

Built with â¤ï¸ for the local AI community
